{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNKlWfiO5jvnyuWFVCfWblg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedamusk/AI-N-ML/blob/main/scratchdecision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "import graphviz"
      ],
      "metadata": {
        "id": "d8d3Bk0aEzLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Class\n",
        "The `Node` class represents a single node in a decision tree. Each node may store information necessary for making a decision or classification and contains pointers to its child nodes.\n",
        "\n",
        "###Attributes:\n",
        "* `feature_idx` (`int`): Index of the feature used to split the data at this node. Default is `-1`, which indicates the node is a leaf or uninitialized.\n",
        "* `threshold` (`float`): The value at which the feature is split. Default is `0.0`.\n",
        "* `label`(`int`): Class lael assigned to the node. Used when the node is leaf. Default is `-1`.\n",
        "* `left` (`Node` or `None`): Pointer to the left hild node (i.e., the subtree where feature value is <= threshold). Default is `None`.\n",
        "\n",
        "\n",
        "The class is typically used when building decision trees manually."
      ],
      "metadata": {
        "id": "9GlgUe2AGB2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xxzd-k951Q7"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self):\n",
        "    self.feature_idx=-1\n",
        "    self.threshold=0.0\n",
        "    self.label=-1\n",
        "    self.left=None\n",
        "    self.right=None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate gini\n",
        "Calculates the Gini impurity of a dataset, which is a measure of how often a randomly chosen element from the dataset would be incorrectly labelled if it were randomly chosen according to the label distribution in the dataset\n",
        "\n",
        "### Parameters:\n",
        "* `samples` (`list` of `list` or `tuple`): Each sample is expected to be a list or tuple where the label is stored at index `2`. The function assumes binary classification, which class labels `0` and `1`.\n",
        "\n",
        "### Returns:\n",
        "* `float`: The Gini impurity value ranging from `0.0` (pure) to `0.5` (maximum impurity for binary classes).\n",
        "\n",
        "### How it works:\n",
        " 1. If the input `samples` list is empty, the function returns `0.0` (no impurity).\n",
        " 2. It counts how many samples belong to class `0` and class `1`.\n",
        " 3. It computes the proportion of each class.\n",
        " 4. It applies the Gini formula:\n",
        "  $\n",
        "  \\text{Gini}=1 - \\sum_{i=1}^{n} p_i^2\n",
        "  $\n",
        "  Where $p_i$ is the probability of class $i$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xfg5nm70INKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gini(samples):\n",
        "  if not samples:\n",
        "    return 0.0\n",
        "  count=[0, 0]\n",
        "  for sample in samples:\n",
        "    count[int(sample[2])]+=1\n",
        "  total=len(samples)\n",
        "  gini=1.0\n",
        "  for c in count:\n",
        "    p=c/total\n",
        "    gini-=p*p\n",
        "  return gini"
      ],
      "metadata": {
        "id": "ZiWCwFDP85rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find best split\n",
        "\n",
        "Finds the best feature and threshold to split a dataset in order to minimize the Gini impurity. This function is used in building decision trees for classification.\n",
        "\n",
        "### Parameters\n",
        "* `samples` (`list` of `list` or `tuple`): Each sample is expected to have feature values at index `0` and `1`, and the class label at index `2`.\n",
        "\n",
        "### Returns:\n",
        "* `tuple`:\n",
        "  * `best_feature` (`int`): Index of the feature (0 or 1) that gives the best split.\n",
        "  * `best_threshold` (`float`): Threshold values for the best split.\n",
        "  * `best_gini` (`float`): The Gini impurity score of the best split (lower is better).\n",
        "\n",
        "### How it works:\n",
        "1. Initializes the best Gini score as infinity and placeholders for the best feature and threshold.\n",
        "2. Iterates over each feature (in this case, feature 0 and 1).\n",
        "3. For each feature, gathers unique values (used as possible thresholds) and sorts them.\n",
        "4. For each threshold:\n",
        "  * Splits the dataset into two groups: `left` (values <= threshold) and `right` (values > threshold).\n",
        "  * Skips the threshold if either split is empty.\n",
        "  * Calculates Gini impurity for both groups and omputes the weighted Gini of the Gini Split.\n",
        "\n",
        "5. Keeps track of the feature and threshold that produces the lowest weighted Gini impurity.\n",
        "6. Returns the best feature index, threshold, and more corresponding Gini sco\n",
        "\n"
      ],
      "metadata": {
        "id": "sQnpcK8OPCkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(samples):\n",
        "  best_gini=float('inf')\n",
        "  best_feature=-1\n",
        "  best_threhsold=0.0\n",
        "\n",
        "  for feature in range(2):\n",
        "    thresholds=sorted(set(sample[feature] for sample in samples))\n",
        "\n",
        "    for thresh in thresholds:\n",
        "      left=[s for s in samples if s[feature]<=thresh]\n",
        "      right=[s for s in samples if s[feature]> thresh]\n",
        "      if not left or not right:\n",
        "        continue\n",
        "\n",
        "      gini_left=calculate_gini(left)\n",
        "      gini_right=calculate_gini(right)\n",
        "      weighted_gini=(len(left)*gini_left+len(right)*gini_right)\n",
        "\n",
        "      if weighted_gini< best_gini:\n",
        "        best_gini=weighted_gini\n",
        "        best_feature=feature\n",
        "        best_threshold=thresh\n",
        "\n",
        "  return best_feature, best_threshold, best_gini"
      ],
      "metadata": {
        "id": "tNq1of_u9thp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Tree\n",
        "Recursively builds a binary decision tree using the Gini impurity criterion. The tree is constructed by choosing the best feature and threshold at each node to split the data, until a maximum depth is reached or further splitting is unnecessary.\n",
        "\n",
        "### Parameters\n",
        "* `samples` (`list` of `list` of `tuple`): Each sample must have at least three elements: feature 0, feature 1 and a label at index 2.\n",
        "* `depth` (`int`): the current depth of the tree (starts at 0 when first caled).\n",
        "* `max_depth` (`int`): The maximum depth allowed for the tree.\n",
        "\n",
        "### Returns:\n",
        "* `Node`: The rrot node of the (sub)tree, containing split information or a predicted label.\n",
        "\n",
        "### How it works\n",
        "1. Creates a new `Node` instance.\n",
        "2. Checks stopping conditions:\n",
        "  * If the maximum depth is reached.\n",
        "  * If there are fewer than 2 samples.\n",
        "  * If the Gini Impurity is 0 (pure node). In these cases, the node becomes a leaf, and the majority class label is assigned.\n",
        "\n",
        "3. Otherwise, the function:\n",
        "  * Finds the best feature and threshold to split the samples using `find_best_split`.\n",
        "  * Splits the dataset into `left_samples` and `right_samples`.\n",
        "  * Recursively builds the left and right subtrees.\n",
        "  * Sets the node's feature index and threshold, and attaches the child nodes."
      ],
      "metadata": {
        "id": "LV3eyW4hfLIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(samples, depth, max_depth):\n",
        "  node=Node()\n",
        "\n",
        "  current_gini=calculate_gini(samples)\n",
        "  if depth>= max_depth or len(samples)<2 or current_gini==0.0:\n",
        "    count=[0,0]\n",
        "    for sample in samples:\n",
        "      count[int(sample[2])]+=1\n",
        "    node.label=1 if count[1]>count[0] else 0\n",
        "    return node\n",
        "\n",
        "  best_feature, best_threshold, _=find_best_split(samples)\n",
        "\n",
        "  left_samples=[s for s in samples if s[best_feature]<=best_threshold]\n",
        "  right_samples=[s for s in samples if s[best_feature]>best_threshold]\n",
        "\n",
        "  node.feature_idx=best_feature\n",
        "  node.threshold=best_threshold\n",
        "  node.left=build_tree(left_samples, depth+1, max_depth)\n",
        "  node.right=build_tree(right_samples, depth+1, max_depth)\n",
        "  return node"
      ],
      "metadata": {
        "id": "cTL35Wc9-uJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "Predicts the class label for a single input sample using a decision tree built with `Node` objects.\n",
        "\n",
        "### Parameters\n",
        "* `node` (`Node`): The current node in the decision tree (typically the root node when called initially).\n",
        "* `sample` (`list` or `tuple`): A single input sample, where the number of features matches what was used to train the tree.\n",
        "\n",
        "### Returns\n",
        "* `int`: The predicted class label (e.g., `0` or `1`)\n",
        "\n",
        "### How it works\n",
        "1. Base case: If the current node is a leaf (i.e., `node.label !=-1`), it returns the label stored in that node.\n",
        "2. Recursive cas: It checks the feature at `node.feature_idx`:\n",
        "  * If the sample's value at that index is less than or equal to the node's threshold, it continues down the left subtree.\n",
        "  * Otherwise, it goes down the right subtree.\n",
        "\n",
        "3. The function continues traversing unitl it reaches a leaf node and returns the final label.\n"
      ],
      "metadata": {
        "id": "ow3vYzJnl3y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(node, sample):\n",
        "  if node.label !=-1:\n",
        "    return node.label\n",
        "  if sample[node.feature_idx]<=node.threshold:\n",
        "    return predict(node.left, sample)\n",
        "  return predict(node.right, sample)"
      ],
      "metadata": {
        "id": "CyO5WDv6AUnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree dot\n",
        "Generates a Graphviz DOT representation of a decision tree for visualization purposes. Each node in the tree is represented either as a box (leaf node with class label) or an oval (internal decision node).\n",
        "\n",
        "###Parameters:\n",
        "* `node1 (`Node`): The root node of the decision tree.\n",
        "* `dot` (`graphvix.Diagraph`, optional): A `Diagraph` object used for recursive calls. On te first call, this should be left as `None`.\n",
        "\n",
        "### Returns:\n",
        "* `graphviz.Diagraph`: A `Diagraph` object representing the struture of the tree, ready for rendering or exporting.\n",
        "\n",
        "### How it works:\n",
        "1. Initial setup: If `dot` is `None`, creates a new `Diagraph` instance and sets the direction from top to bottom.\n",
        "2. Node identification: Uses Python's `id()` to generate a unique identifier for each node.\n",
        "3. Node labels:\n",
        "  * Leaf nodes: Displayed as boxes with the predicted class (`Igneous` for label 1, `Sedimentary` for label 0).\n",
        "  * Internal nodes: Displayed as ovals with the decision rule (e.g., `Silica <= threshold` or `Grain Size<=threshold`).\n",
        "4. Edges: Adds edges from the current node to its left and right children, if they exist.\n",
        "5. Recursively calls itself to continue building the tree structure."
      ],
      "metadata": {
        "id": "Zra3voWDsMnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tree_to_dot(node, dot=None):\n",
        "  if dot is None:\n",
        "    from graphviz import Digraph\n",
        "    dot=Digraph()\n",
        "    dot.attr(rankdir='TB')\n",
        "\n",
        "  node_id=str(id(node))\n",
        "\n",
        "  if node.label != -1:\n",
        "    label=f\"Class: {'Igneous' if node.label==1 else 'Sedimentary'}\"\n",
        "    dot.node(node_id, label, shape='box')\n",
        "  else:\n",
        "    feature_name='Silica' if node.feature_idx==0 else 'Grain Size'\n",
        "    label=f\"{feature_name}\\n<= {node.threshold:2f}\"\n",
        "    dot.node(node_id, label, shape='oval')\n",
        "\n",
        "  if node.left:\n",
        "    dot.edge(node_id, str(id(node.left)))\n",
        "    tree_to_dot(node.left, dot)\n",
        "  if node.right:\n",
        "    dot.edge(node_id, str(id(node.right)))\n",
        "    tree_to_dot(node.right, dot)\n",
        "\n",
        "  return dot"
      ],
      "metadata": {
        "id": "_yZXT2NJBdl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script execution block\n",
        "This section runs when the script is excuted directly. It demonstrates how to build a decision tree for classifying rock types (Igneous vs. Sedimentary) based on silica content an grain size, mae predictions, and visualize the tree."
      ],
      "metadata": {
        "id": "xqzxJgfOHFB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  dataset=[\n",
        "      [70.0, 1.0, 1], #Igneous\n",
        "      [55.0, 0.5, 1], #Igneous\n",
        "      [65.0, 2.0, 1], #Igneous\n",
        "      [30.0, 0.1, 0], #Sedimentary\n",
        "      [40.0, 1.5, 0], #Sedimentary\n",
        "      [50.0, 0.05, 0] #Sedimentary\n",
        "  ]\n",
        "\n",
        "  \"\"\"Each sample is structures as [Silica %, Grain size(mm), Label], where Label\n",
        "  is 1 for Igneous and 0 for sedimentary\"\"\"\n",
        "\n",
        "  root=build_tree(dataset, 0, 2) #Builds the decision tree from the dataset, starting at depth 0, with a max depth of 2\n",
        "\n",
        "  print(\"Testing rock sample\")\n",
        "  test_samples=[\n",
        "      [60.0, 1.2], #Expected: Igneous\n",
        "      [35.0, 0.2], #Expected: Sedimentary\n",
        "  ]\n",
        "  \"\"\"Predicts the class label for each sample and prints the result\"\"\"\n",
        "\n",
        "  for sample in test_samples:\n",
        "    pred=predict(root, sample)\n",
        "    print(f\"Silica: {sample[0]}%, Grain Size: {sample[1]}mm -> {'Igneous' if pred else 'Sedimentary'}\")\n",
        "\n",
        "    try:\n",
        "      dot=tree_to_dot(root)\n",
        "      dot.render(\"rock_decision_tree\", format=\"png\", cleanup=True)\n",
        "      print(\"\\nDecision tree visualization saved as 'rock_decision_tree.png'\")\n",
        "    except Exception as e:\n",
        "      print(\"Couldn't create visualization. Make Sure graphviz is installed\")\n",
        "      print(\"!pip install graphviz\")\n",
        "      print(\"Also ensure Grphviz is installed on your system\")"
      ],
      "metadata": {
        "id": "7W6vTJXHCltG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}