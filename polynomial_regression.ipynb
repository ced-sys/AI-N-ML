{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN728JgeHeuSLu7w+SgYpP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedamusk/AI-N-ML/blob/main/polynomial_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2Eb-WunLhP7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Modules\n",
        "1. `numpy`: Provides support for numerical operations on arrays and matrices. Used for creating and manipulating numerical data in arrays.\n",
        "\n",
        "2. `pandas`: A data manipulation and analysis library. Used for loading, cleaning and organizing the dataset into a structures format like a DataFrame.\n",
        "\n",
        "3. `matplotlib.pyplot`: A plotting library for creating visualizations. Used for generating scatter plots, regression curves, and other data visualizations.\n",
        "\n",
        "4. `sklearn.preprocessing.PolynomialFeatures`: Part of `scikit-learn`. Generates polynomial features from the original input data. For example, if the input is X, it generates X, X^2, X^3... based on the specified polynomial degree.\n",
        "\n",
        "5. `sklearn.linear_model.LinearRegression`: Provides the implementation of linear regression. Used for fitting a linear regression model to the transformed polynomial features.\n",
        "\n",
        "6. `sklearn.model_selection.train_test_split`: Splits the dataset into training and testing subsets. Ensures the model is trained on one part of the data and validated on another, reducing overfitting."
      ],
      "metadata": {
        "id": "vx6ZtJuOmmyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "s5QJLSM9LtCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the dataset\n",
        "1. `df=pd.read_csv('synthetic_polynomial_data.csv')`: Loads the dataset from the file into a pandas DataFrame named `df`.\n",
        "\n",
        "2. `print(\"First few rows\")`: Displays a title indicating the intention to show the first few rows of the dataset.\n",
        "\n",
        "3. `print(df.head())`: Prints the first 5 rows of the DataFrame (`df`) to give a quick look at the data structure and its initial entities.\n",
        "\n",
        "4. `print(\"\\nDataset info:\")`: Prints a title indicating the intention to display descriptive statistics about the dataset.\n",
        "\n",
        "5. `print(df.describe())`: Displays summary statistice of the numerical column in the DataFrame such as:\n",
        "\n",
        "\n",
        "*   **Count**: Number of non-missing entries.\n",
        "*   **Mean**: Average value\n",
        "*   **Std**: Standard Deviation\n",
        "*   **Min/Max**: Minimum and Maximum values.\n",
        "*   **25%, 50%, 75%**: Percentile values.\n",
        "\n"
      ],
      "metadata": {
        "id": "S4Q0eIO7pwpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('synthetic_polynomial_data.csv')\n",
        "print(\"First few rows\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "1xklSDwCVfyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "This code prepares the data for use in the polynomial regression model by extracting features (`X`) and target (`y`) values.\n",
        "\n",
        "1. `X=df['X'].values`: Extracts the `X` column from the DataFrame (`df`) as a NumPy array using the `.values` attribute. This represents the input (independent variable) for the regression model.\n",
        "2. `.reshape(-1, 1)`: Reshapes the 1D array of `X` into a 2D array with one column and as many rows as needed. This is necessary because `scikit-learn` expects th input to have a 2D shape for features (e.g., `(n_samples, n_features)`)\n",
        "\n",
        "3. `y=df['Y'].values`: Extracts the `Y` column as a NumPy array. Represents the output (dependent variable) for the regression model.\n",
        "\n",
        "##Purpose\n",
        "`X`: A 2D array of independent variable, suitable for use in `scikit-learn` models.\n",
        "`y`: A 1D array of the dependent variable, ready for regression fitting and evaluation."
      ],
      "metadata": {
        "id": "dnodJ-i4wWs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df['X'].values.reshape(-1,1)\n",
        "y=df['Y'].values"
      ],
      "metadata": {
        "id": "AmpCQSH2WgiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize settings\n",
        "This code initializes variables and settings to evaluate polynomial regression models with different degrees.\n",
        "\n",
        "1. `degrees=[2,3,4]`: Defines a ist of polynomial degress to explore: quadratic(2), cubic(3), and quartic(4).\n",
        "\n",
        "2. `best_r2=-np.inf`: Initializes `best_r2` with a very low value (-infinity) to track the best R^2 score across all evaluated models.\n",
        "3. `best_degree=2`: Initializes `best_degree` with 2 (quadratic). This variable will store the degree of the polynomial model with the highest R^2 score.\n",
        "\n",
        "4. `best_model=None`: Initializes `best_model` as `None`. This will store the polynomial feature transformation corresponding to the best performing model.\n",
        "\n",
        "##Purpose\n",
        "The code setups the foundation for iteratively training polynomial regression models for different degrees, keeping track of the best performing model based on the R^2 score, and identifying the optimal polynomial degree associated model/feature transformation."
      ],
      "metadata": {
        "id": "kuwG0ifcx_Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degrees=[2,3,4]\n",
        "best_r2=-np.inf\n",
        "best_degree=2\n",
        "best_model=None\n",
        "best_poly_features=None\n",
        "\n"
      ],
      "metadata": {
        "id": "9QMJnJJcXaI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot\n",
        "This code initializes a new figure for creating a plot with specific dimensions using Matplotlib.\n",
        "1. `plt.figure()`: Creates a new figure for plotting. Ensures any plots created after this line appear within this figure.\n",
        "2. `figsize=(15, 10)`: Sets the size of the figure in inches: 15 inches wide and 10 inches tall. Larger dimensions provide more space, making plots easier to read and interpret."
      ],
      "metadata": {
        "id": "Lz57K_buGt1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))"
      ],
      "metadata": {
        "id": "av2Cv2yVXsZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial regression for different degrees\n",
        "This code iteratively fits polynomial regression models for differet degrees, evaluates them, and visualizes the results.\n",
        "\n",
        "1.`for i, degree in enumerate(degrees, 1):` : Loops through each polynomial degree in the `degrees` list (`[2,3,4]`). `i` is the subpot index (starts from 1).\n",
        "\n",
        "2. `poly_features=PolynomialFeatures(degree=degree, include_bias=False)`: Creates polynomial features for the current degree.  `include_bias=False` ensures no constant term (bias) is added explicitly.\n",
        "\n",
        "3. `X_poly=poly_features.fit_transform(X)`: Transform the input data `X` into polynimial features for the current degree.\n",
        "\n",
        "4. `model=LinearRegression()`: Initializes a linear regression model.\n",
        "\n",
        "5. `model.fit(X_poly, y)`: Trains the linear regression model using the polynomial features (`X_poly`) and target values (`y`).\n",
        "\n",
        "6. `y_pred=model.predict(X_poly)`: Predicts `y` values using the trained model.\n",
        "\n",
        "7. `r2=r2_score(y, y_pred)` and `mse=mean_squared_error(y, y_pred)`: Calculate the R^2 score and Mean Squared Error (MSE) to evaluate the model's performance.\n"
      ],
      "metadata": {
        "id": "Sj5AbkOzKUs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "#Set the style\n",
        "with sns.axes_style('darkgrid'):\n",
        "  plt.rcParams['font.family']='sans-serif'\n",
        "  plt.rcParams['font.sans-serif']=['Arial']\n",
        "\n",
        "#Create a figure with adjusted size and spacing\n",
        "fig=plt.figure(figsize=(12, 4*len(degrees)))\n",
        "fig.subplots_adjust(hspace=0.4)\n",
        "\n",
        "#Color palette for different degrees\n",
        "colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEEAD', '#D4A5A5']\n",
        "\n",
        "for i, degree in enumerate(degrees, 1):\n",
        "  poly_features=PolynomialFeatures(degree=degree, include_bias=False)\n",
        "  X_poly=poly_features.fit_transform(X)\n",
        "  model=LinearRegression()\n",
        "  model.fit(X_poly, y)\n",
        "  y_pred=model.predict(X_poly)\n",
        "  r2=r2_score(y, y_pred)\n",
        "  mse=mean_squared_error(y, y_pred)\n",
        "\n",
        "  #Update the model if necessary\n",
        "  if r2>best_r2:\n",
        "    best_r2=r2\n",
        "    best_degree=degree\n",
        "    best_model=model\n",
        "    best_poly_features=poly_features\n",
        "\n",
        "  #Create subplot with enhanced styling\n",
        "  ax=plt.subplot(len(degrees), 1, i)\n",
        "\n",
        "  #Set background color\n",
        "  ax.set_facecolor('#f9f9fa')\n",
        "\n",
        "  #plot scatter points with enhanced appearance\n",
        "  plt.scatter(X, y, color='#2C3E50', alpha=0.6, label='Actual data', edgecolor='white', s=80)\n",
        "\n",
        "  #Create smooth curve for polynomial fit\n",
        "  X_range=np.linspace(X.min(), X.max(), 300).reshape(-1,1)\n",
        "  X_range_poly=poly_features.transform(X_range)\n",
        "  y_range_pred=model.predict(X_range_poly)\n",
        "\n",
        "  #Plot the polynimials curve with custom color\n",
        "  plt.plot(X_range, y_range_pred, color=colors[i% len(colors)],\n",
        "           label=f'Polynomial degree{degree}', linewidth=2.5)\n",
        "\n",
        "  #Enhanced title and labels\n",
        "  plt.title(f'Polynomial Regression(Degree {degree})\\n$R^2={r2:.4f}$, MSE={mse:.4f}',\n",
        "            pad=20, color='#2C3E50', fontsize=12, fontweight='bold')\n",
        "\n",
        "  plt.xlabel(\"X\", color='#2C3E50', fontsize=10, fontweight='bold')\n",
        "  plt.ylabel(\"Y\", color='#2C3E50', fontsize=10, fontweight='bold')\n",
        "\n",
        "  legend=plt.legend(frameon=True, fancybox=True, shadow=True)\n",
        "  legend.get_frame().set_facecolor('white')\n",
        "\n",
        "  plt.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "  ax.spines['top'].set_visible(False)\n",
        "  ax.spines['right'].set_visible(False)\n",
        "  ax.spines['left'].set_color('#2C3E50')\n",
        "  ax.spines['bottom'].set_color('#2C3E50')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sI-90orZXyqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MESQMSlPZARe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\nbest polynomial degree: {best_degree}')\n",
        "print(f\"best r2 score: {best_r2:.4f}\")"
      ],
      "metadata": {
        "id": "0L_eHQlVazVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "The code generats a polynomial equation string from the coefficeints of the `best_model`, which was determined in the earlier loop as the best-fit polynomial regression model."
      ],
      "metadata": {
        "id": "SLGRaLJT-P1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients=best_model.coef_\n",
        "equation=\"Y =\"\n",
        "for i, coef in enumerate(coefficients):\n",
        "  if i==0:\n",
        "    equation += f\"{coef:.4f}X\"\n",
        "  else:\n",
        "    equation += f\" + {coef:.4f}X^{i+1}\""
      ],
      "metadata": {
        "id": "GW1BBZenbhPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBest fitting polynomial equation:\")\n",
        "print(equation)"
      ],
      "metadata": {
        "id": "1igZu2D2b8dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_years=np.array([[11], [12], [13]])\n",
        "future_X_poly=best_poly_features.transform(future_years)\n",
        "future_predictions=best_model.predict(future_X_poly)\n"
      ],
      "metadata": {
        "id": "EDwYowbYcHud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPredictions or future X values:\")\n",
        "for year, pred in zip(future_years.flatten(), future_predictions):\n",
        "  print(f\"X={year}: Y={pred:.4f}\")\n"
      ],
      "metadata": {
        "id": "A1FIid1gctwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}